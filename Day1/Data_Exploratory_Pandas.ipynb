{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is pandas ?\n",
    " - Panda is an open source library in python for data analysis, data maupulation and data visulaization\n",
    " - its built top on numpy, scipy\n",
    " - Anaconda distribution include the pandas along with other packages installation by default\n",
    " - Ref : \n",
    " - http://pandas.pydata.org/\n",
    " - https://pandas.pydata.org/pandas-docs/stable/basics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pypi - is repository for open-source third party packages available in python.\n",
    "#        we can use pip install at the command line to install those packages.\n",
    "#      - we can use conda install to get the libraries avaialable in Conda Manager\n",
    "#        !conda list pandas - to check if the package 'pandas' is already installed\n",
    "#        !pip install 'package_name' or !conda install 'package_name' to install package from notebook\n",
    "\n",
    "# Ref - http://doc.pypy.org/en/latest/install.html ,  http://packages.pypy.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis using Numpy, Scipy, Pandas, Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series : \n",
    "- One-dimensional series of indexed data, can be created from a list or arrays.\n",
    "- Series has data value and index, data can be accessed by associated index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1,2,3,4,5])  # \n",
    "ser1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1[0] # 0th Index\n",
    "ser1[4] # 4th Index\n",
    "ser1[1:3] # select form 1st to (3-1)2nd index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([1,2,3,4,5], index=('a','b','c','d','e'))  # Pandas series is just like numpy array, only diff is numpy index\n",
    "ser1                                                        # is implictly defined while in pd series explictly defined index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrame - is a collection of pandas Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics Objective : Based on Historical advertising data, discover the relationship of advertisement with Sales and  recommend the marketing plan to result in high Product sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from local disk\n",
    "sales_data = pd.read_csv('C:\\\\Users\\\\jp\\\\Desktop\\\\testData\\\\Advertising.csv')\n",
    "\n",
    "\n",
    "# reading the data from web\n",
    "# temp_data = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', sep=',', header=None)\n",
    "# temp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Attributes and underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()  # top five records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors or Features or dependent Variable\n",
    "- TV : advertising budgets(in thousands of dollars) spent on TV ads for a single product in a market.\n",
    "- Radio : advertising budgets(in thousands of dollars) spent on Radio ads.\n",
    "- Newspaper : advertising budgets(in thousands of dollars) spent on Newspaper ads.\n",
    "\n",
    "### Response or Independent Variable\n",
    "- Sales : Sales of a single product in a given market (in thousands units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.tail() # bottom 5 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.size  # return the number of elements in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.shape  # return the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.dtypes # return the dtypes of each column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.ndim # return the number of axes ( 1 - Pandas series, 2 - Pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.empty # Indicator whether dataframe is empty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.memory_usage() # return memory usage of each column in bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.axes # return the list representing the axes of the dataframe (row axis labels, column axis labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.columns  # Retrieving the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.index # Retrieving the Index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.values # return only the values from dataframe in the numpy representation, the axes labels will be removed  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Selection, Sorting, Rename, Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a column\n",
    "sales_data[['TV']].head()\n",
    "\n",
    "#sales_data.TV.head()\n",
    "#sales_data[['TV', 'Radio']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the Data Frame\n",
    "sales_data.sort_values(by='TV').head()  # Sorted basedon TV-advt-expenses values, default is in asceding order sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.sort_values(by='TV', ascending=False).head()  # Sorted in descending order based on TV-add-expense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dropping a cloumn\n",
    "sales_data.drop('Sales', axis=1).head()\n",
    "#sales_data.drop('Sales', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping a row\n",
    "sales_data.drop(2, axis=0).head()  \n",
    "#sales_data.drop([1,3], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#renaming the colum names \n",
    "sales_data.rename(columns = {'Area' : 'AreaName'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Records selection subsetings\n",
    "\n",
    "- Selection by poistion : df.iloc - (purely integer based indexing)\n",
    "- Selection by labels : df.loc   - (label based indexing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[:10] # first 10 rows selection, with all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[2:5] # select from 2nd index to 4th index, with all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[0:4, 0:3 ]  # Row selector (0:4) - From 0th index to 3rd index rows, Columns Selectors (0:3) - 0th to 2nd columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[[2,5,10] , 0:3 ]  # select the specific row index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data[['TV','Radio']].iloc[0:4]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[0:3 , : ]  # first 3 rows with all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.iloc[: , 0:3].head()   # select all rows, with first three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to use lable indexing where index are not integers\n",
    "import numpy as np\n",
    "\n",
    "dates = pd.date_range('1/1/2016', periods=6, freq='D')\n",
    "#df1 = pd.DataFrame(np.random.randn(6, 4), columns=['a','b','c','d'])\n",
    "df1 = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=['a','b','c','d'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc['2016-01-01']  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc['2016-01-02', :  ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc['2016-01-02':'2016-01-04', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering - Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering a row from a panda data frame \n",
    "\n",
    "# Single Filter - list out all the records where TV advertisement expese > 250\n",
    "sales_data[sales_data.TV > 250].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mulitple Filter - list out all the records where TV advertisement expese > 250 and area='rural'\n",
    "sales_data[(sales_data.TV > 250) & (sales_data.Area == 'rural')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mulitple Filter - list out all the records where TV advertisement expese > 250 or area='rural'\n",
    "sales_data[(sales_data.TV > 250) | (sales_data.Area == 'rural')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the records where TV Advt budget = 800\n",
    "sales_data[sales_data.TV == 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the records where TV Advt budget = 800  and 286   - isin()\n",
    "temp_data = sales_data[sales_data.TV.isin([800, 286])]\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the file into disk\n",
    "temp_data.to_csv('temp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group By "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of sales_txn under each area : \n",
    "sales_data.groupby('Area').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise - Get the total Transactions for each Prod_type under each Area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.Area.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.Area.value_counts(normalize=True)\n",
    "\n",
    "#sales_data.groupby(['Area','Prod_type']).size()\n",
    "#sales_data.groupby(['Prod_type', 'Area']).size()\n",
    "#sales_data.groupby('Area').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise - get the total sum of each attributes TV, Radio, Newspaper, Sales for each Area\n",
    "#          - get the summary statistics for each attributes for each Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.describe()\n",
    "#sales_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.groupby('Area').describe()\n",
    "\n",
    "#sales_data.groupby('Area').describe().transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - Load the IPL data and coplete the three level of exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_data.groupby('Area').std() , sales_data.groupby('Area').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Features - SKLEARN\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)\n",
    "\n",
    "What are the categorical features in our dataset?\n",
    "\n",
    "- **Ordered categories:** weather (already encoded with sensible numeric values)\n",
    "- **Unordered categories:** season (needs dummy encoding), holiday (already dummy encoded), workingday (already dummy encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "emp_data ={\"emp_id\":[1,2,3,4,5,6,7,8,9,10],\"income\":[\"high\",\"low\",\"low\",\"high\",\"high\",\"low\",\"low\",\"high\",\"high\",\"low\"]}\n",
    "\n",
    "emp_df = pd.DataFrame(emp_data) # 10 employees data\n",
    "emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.dtypes  # income columns in string literals, we want to map it to numerical values as high=1, low=0 ( Ordinal categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Using Pandas Categorical Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pandas Categorical Encoding \n",
    "# first convert that column data type as categorical and then apply pandas encoding for each categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categoricals are a pandas data type, which correspond to categorical variables in statistics:\n",
    "# a variable, which can take on only a limited, and usually fixed, number of possible values \n",
    "emp_df['income_code2'] = emp_df['income'].astype('category') # Pandas categorical data types (compact data types, ordering)\n",
    "emp_df.dtypes\n",
    "#emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.income_code2.cat.categories  # category listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catgorical encoding\n",
    "emp_df['income_code2'] = emp_df.income_code2.cat.codes  # (encoded categories to numbers in alphnumeric order, high=0, low=1)\n",
    "emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ordering of categories \n",
    "emp_df['income_code3'] = emp_df['income'].astype(\"category\", categories = ['low','high'])\n",
    "emp_df.income_code3.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df['income_code3'] = emp_df.income_code3.cat.codes  \n",
    "emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - define a function to map each categories to numerical value and apply for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tran_incode(x):\n",
    "    if x== \"high\":\n",
    "        return 5\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "#     if x == \"low\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_incode('high')\n",
    "#tran_incode('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new coded column by applying this function to each row of data frame\n",
    "emp_df['income_code4'] = emp_df.income.apply(tran_incode)\n",
    "emp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot coding  Categorical Variables  - Nominal Categories\n",
    "- Convert each category to a new column and assign a value of 0 or 1.\n",
    "- Use pandas get_dummies() function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.get_dummies(emp_df, columns=['income']) # we can pass many categories to get converted into dummy variables\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical to Categorical - Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = pd.DataFrame()\n",
    "test_df2['CTC'] = [10, 5, 25.4, 56.4, 76.1, 92.1, 45.3, 1.5, 7.5]\n",
    "\n",
    "test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_bins = [0, 5, 10, 25, 50, 75, 100]\n",
    "labels = [1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['bin_range'] = pd.cut(test_df2['CTC'], CTC_bins)  # (Bin (5,10) - 5 excluding, 10 including)\n",
    "test_df2['CTC_binned'] = pd.cut(test_df2['CTC'], CTC_bins, labels=labels)\n",
    "test_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the missing values in each column\n",
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the missing values in each row\n",
    "sales_data.isnull().sum(axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows where Radio column has missing values\n",
    "sales_data[sales_data.Radio.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows where Newspaper column has missing values\n",
    "sales_data[sales_data.Newspaper.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows that has any missing value\n",
    "sales_data[sales_data.isnull().any(axis=1)] \n",
    "\n",
    "#sales_data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing imputation - drop or impute with estimated values\n",
    "\n",
    "# dropna() - Dropping the rows havng missing values\n",
    "# fillna() - Imputing the missing values\n",
    "\n",
    "# sales_data = sales_data.dropna()  # drop the rows having missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values with mean\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# calculate the mean\n",
    "Radio_mean = np.mean(sales_data.Radio)\n",
    "Radio_mean\n",
    "\n",
    "# # # # # # # Replace missing values with the mean\n",
    "sales_data.Radio = sales_data.Radio.fillna(Radio_mean)\n",
    "\n",
    "sales_data\n",
    "\n",
    "Newspaper_mean = np.mean(sales_data.Newspaper)\n",
    "sales_data.Newspaper = sales_data.Newspaper.fillna(Newspaper_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with the mean\n",
    "sales_data.Radio = sales_data.Radio.fillna(np.mean(sales_data.Radio))\n",
    "sales_data.Newspaper = sales_data.Newspaper.fillna(np.mean(sales_data.Newspaper))\n",
    "\n",
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge - Combining diff dataframe\n",
    "- Join\n",
    "- Concantnate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge - Concatnate\n",
    "df_1 = pd.DataFrame(np.random.randn(5, 4), columns=['a','b','c','d'])\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(np.random.randn(3, 4), columns=['a','b','c','d'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_1, df_2], axis=0)   # row level merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_1, df_2], axis=0).reset_index(drop=True) # reseting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dataframes having diff structures\n",
    "df_3 = pd.DataFrame(np.random.randn(3, 5), columns=['a','b','c','d','e'])\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merging df_1 and df_3\n",
    "pd.concat([df_1, df_3], axis=0)              # default is outer join based merge\n",
    "#pd.concat([df_1, df_3], axis=0, join='inner') # inner join based merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column level merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.DataFrame(np.random.randn(3, 2), columns=['f','g'])\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_3, df_4], axis=1)  # Column level merging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.DataFrame(np.random.randn(4, 2), columns=['f','g'])\n",
    "df_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_3, df_5], axis=1)               # outer join (by default)\n",
    "#pd.concat([df_3, df_5], axis=1, join='inner')  # inner join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join - SQL Style merging two data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merger two data frame\n",
    "\n",
    "left_df = pd.DataFrame({'Txn' : ['txn1', 'txn2', 'txn3', 'txn4'], 'Item' : ['i1', 'i2', 'i3', 'i4'], 'Value' : [100, 200, 400, 400]}, columns=['Txn','Item','Value'])\n",
    "left_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_df = pd.DataFrame({'Item' : ['i1', 'i2', 'i3', 'i5'], 'Item_Descr' : ['Item_1', 'Item_2', 'Item_3', 'Item_5']})\n",
    "right_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_df, right_df, on='Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_df, right_df, how = 'inner', left_on='Item', right_on='Item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left_df, right_df, how = 'outer', left_on=['Item'], right_on= ['Item'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = pd.DataFrame(np.random.randn(3, 4), columns=['A','B','C','D'])\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df_10\n",
    "df_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11.iloc[0,0] = 5.5  # updating a value explictly\n",
    "df_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = df_10.copy()  # Make a copy of the data and the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12.iloc[1,1] = 6.6\n",
    "df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max number of columns display setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 30)\n",
    "#pd.set_option(\"display.max_columns\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
