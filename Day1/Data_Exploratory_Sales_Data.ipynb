{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis using Numpy, Scipy, Pandas, Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics Objective : Based on Historical advertising data, discover the relationship of advertisement with Sales and  recommend the marketing plan to result in high Product sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from local disk\n",
    "sales_data = pd.read_csv('C:\\\\Users\\\\jp\\\\Desktop\\\\testData\\\\Advertising.csv')\n",
    "\n",
    "# reading the data from web\n",
    "# temp_data = pd.read_table('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', sep=',', header=None)\n",
    "# temp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe Attributes and underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()  # top five records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors or Features or dependent Variable\n",
    "- TV : advertising budgets(in thousands of dollars) spent on TV ads for a single product in a market.\n",
    "- Radio : advertising budgets(in thousands of dollars) spent on Radio ads.\n",
    "- Newspaper : advertising budgets(in thousands of dollars) spent on Newspaper ads.\n",
    "\n",
    "### Response or Independent Variable\n",
    "- Sales : Sales of a single product in a given market (in thousands units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the missing values in each column\n",
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out all the missing values in each row\n",
    "sales_data.isnull().sum(axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows where Radio column has missing values\n",
    "sales_data[sales_data.Radio.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows where Newspaper column has missing values\n",
    "sales_data[sales_data.Newspaper.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows that has any missing value\n",
    "sales_data[sales_data.isnull().any(axis=1)] \n",
    "\n",
    "#sales_data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list out all the rows  having missing values\n",
    "# nan_rows = sales_data[sales_data.isnull().T.any()]  \n",
    "# nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing imputation - drop or impute with estimated values\n",
    "\n",
    "# dropna() - Dropping the rows havng missing values\n",
    "# fillna() - Imputing the missing values\n",
    "\n",
    "# sales_data = sales_data.dropna()  # drop the rows having missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the missing values with mean\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# calculate the mean\n",
    "Radio_mean = np.mean(sales_data.Radio)\n",
    "Radio_mean\n",
    "\n",
    "# # # # # # # Replace missing values with the mean\n",
    "sales_data.Radio = sales_data.Radio.fillna(Radio_mean)\n",
    "\n",
    "sales_data\n",
    "\n",
    "Newspaper_mean = np.mean(sales_data.Newspaper)\n",
    "sales_data.Newspaper = sales_data.Newspaper.fillna(Newspaper_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Box plot to find outliers - TV\n",
    "sns.boxplot(sales_data.TV, color = \"green\", orient = \"v\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, bp = pd.DataFrame.boxplot(sales_data.TV, return_type='both')\n",
    "outliers = [flier.get_ydata() for flier in bp[\"fliers\"]]\n",
    "outliers\n",
    "\n",
    "#sales_data[sales_data.TV.isin(outliers[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data.drop(sales_data[sales_data.TV == 800].index)\n",
    "sales_data.drop(sales_data[sales_data.TV == 800].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales_data[sales_data.TV == 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Box plot to find outliers - RADIO`\n",
    "sns.boxplot(sales_data.Radio, color = \"green\", orient = \"v\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(sales_data.Sales, color = \"green\", orient = \"v\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarising each attributes. - Measure of Central Tendency (Mean, Median, Mode)\n",
    "sales_data.TV.mean()  # average TV Advertisement expense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarising each attributes. - Measure of Dispersion (Range, Variance, Standard Dev, IQR)\n",
    "sales_data.TV.std()  # Standard Deviation of TV Advertisement expense\n",
    "#sales_data.TV.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarising each attributes.\n",
    "sales_data.Radio.mean()  # average Radio Advertisement expense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### describe() - Summary Statistics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the summary statistics of quantitative attributes\n",
    "sales_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical data  \n",
    "- Area \n",
    "- Prod_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Unique Classes under Area\n",
    "sales_data.Area.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distribuiton of Area\n",
    "sales_data.Area.value_counts()\n",
    "#sales_data.Area.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Plot - Frequency Distribution of Categorical var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fequency Bar plot\n",
    "sns.countplot(x=\"Area\", data=sales_data, palette=\"Greens_d\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prod_type Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Classes under Prod_type\n",
    "sales_data.Prod_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency distribuiton of Prod_type\n",
    "sales_data.Prod_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fequency Bar plot\n",
    "sns.countplot(x=\"Prod_type\", data=sales_data, palette=\"Greens_d\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical attributes, need to pass specifically the 'object' in the describe method\n",
    "sales_data.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram - Frequency distribution of Numeical data bins ( TV - advertisement)\n",
    "sns.distplot(sales_data.TV, bins=10, kde=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the bins values (equal range), we can use np.histogram()\n",
    "import numpy as np\n",
    "np.histogram(sales_data.TV, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization  : \n",
    "- Matplotlib is a core package for visualization. \n",
    "- Seaborn is extension of matplotlib to make griphic look nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bi-Variate Analysis ( Numerical vs Numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot to visulize the realtionship between Marketing_advertisements vs Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bi Variate analysis ( Numerical - Numerical)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "sales_data.plot(kind='scatter', x='TV', y='Sales', ax=axs[0], figsize=(16, 8))\n",
    "sales_data.plot(kind='scatter', x='Radio', y='Sales', ax=axs[1])\n",
    "sales_data.plot(kind='scatter', x='Newspaper', y='Sales', ax=axs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between Numberical Attributes to measure the linear relationship strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(sales_data.corr(method='pearson'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bi-Variate Analysis ( Categorical vs Numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales_data = pd.read_csv('C:\\\\Users\\\\jp\\\\Desktop\\\\testData\\\\Advertising.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the average demands(sales) for each Product_type by using Groupby\n",
    "sales_data.groupby('Prod_type').Sales.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Prod_type\", y=\"Sales\", data=sales_data, ci=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Categorical - Numerical ( Prod_type Vs Sales)\n",
    "sns.boxplot(x=\"Prod_type\", y=\"Sales\", data=sales_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data[sales_data.Prod_type == 'Basic']['Sales'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-test ( Product_Type vs Sales) \n",
    "Basic = sales_data[sales_data.Prod_type == 'Basic']['Sales'] # Sales Demands of Basic Model\n",
    "Higher = sales_data[sales_data.Prod_type == 'Higher']['Sales']\n",
    "Medium = sales_data[sales_data.Prod_type == 'Medium']['Sales']\n",
    "\n",
    "stats.f_oneway(Basic, Higher, Medium) # F-Statistics : mu1 = mu2 = mu3\n",
    "\n",
    "# F Statistics (p-value < .05) => we can reject null hypothesis that avg demands are same for each Product_type. \n",
    "# We can conclude that there is a relationship between categorical var Product_type and Demands(prodcut sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-Test to test if the differrences among the group means are statisticall significant or it is just due to sampling variablitiy.\n",
    "# H0: mu1=mu2=mu3   , F = (Variations among group means) / (Variation within group)\n",
    "\n",
    "model = smf.ols(formula='Sales ~ Area', data=sales_data)\n",
    "results = model.fit()\n",
    "print(results.summary())  # F Statistics (p-value < .05) => we can reject null hypothesis that avg demands are same for each Product_type.\n",
    "                          # We can conclude that there is a relationship between categorical var Product_type and Demands(prodcut sales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average Sales for each Areas by using Groupby - (Does the area has any influence on Sales)\n",
    "sales_data.groupby('Area').Sales.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Area\", y=\"Sales\", data=sales_data, ci=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-test\n",
    "rural_sales = sales_data[sales_data.Area == 'rural']['Sales']\n",
    "suburban_sales = sales_data[sales_data.Area == 'suburban']['Sales']\n",
    "urban_sales = sales_data[sales_data.Area == 'urban']['Sales']\n",
    "\n",
    "stats.f_oneway(rural_sales, suburban_sales, urban_sales) # F-Statistics : mu1 = mu2 = mu3\n",
    "\n",
    "# F Statistics (p-value > .05) => we can not reject null hypothesis that avg demands are same for each Area. \n",
    "# We can conclude that there is no relationship between categorical var Area and Product_Sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Features - SKLEARN\n",
    "\n",
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding (0/1)\n",
    "\n",
    "What are the categorical features in our dataset?\n",
    "\n",
    "- **Ordered categories:** weather (already encoded with sensible numeric values)\n",
    "- **Unordered categories:** season (needs dummy encoding), holiday (already dummy encoded), workingday (already dummy encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise - Categorical encoding and one-hot-coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('C:\\\\Users\\\\jp\\\\Desktop\\\\testData\\\\Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets apply ordingal and nominal encoding on sales_data\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the missing value\n",
    "\n",
    "# # # # # # # Replace missing values with the mean\n",
    "sales_data.Radio = sales_data.Radio.fillna(np.mean(sales_data.Radio))\n",
    "sales_data.Newspaper = sales_data.Newspaper.fillna(np.mean(sales_data.Newspaper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment\n",
    "# Prod_type - Need to be converted into ordinal encoding (Basic=0, Medium=1, Higher=2)\n",
    "# Area - can be done as one-hot-codding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for each categories\n",
    "sales_data.Prod_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert categorical Var Prod_type in ordinal encoding (Basic = 0, Medium = 1, Higher = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prod_type_incode(x):\n",
    "    if x== \"Basic\":\n",
    "        return 1\n",
    "    elif x == \"Medium\" :\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data['Prod_type_cd'] = sales_data.Prod_type.apply(Prod_type_incode)\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.get_dummies(sales_data, columns=['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Regression Model using statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analyze the historical Sales data to discover which Advertise Media generate the biggest boost in Sales and develop a Predictive Model to predict the Sales based on Advertisement Budgets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors or Features or dependent Variable\n",
    "- TV : advertising budgets(in thousands of dollars) spent on TV ads for a single product in a market.\n",
    "- Radio : advertising budgets(in thousands of dollars) spent on Radio ads.\n",
    "- Newspaper : advertising budgets(in thousands of dollars) spent on Newspaper ads.\n",
    "- Area : Area of Sales- Urban, Rural, Suburban\n",
    "- Prod_type : Product Model- Basic, Medium, Higher\n",
    "\n",
    "### Response or Independent Variable\n",
    "- Sales : Sales of a single product in a given market (in thousands units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression Model using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple Linear Regression Model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lmreg = LinearRegression()\n",
    "x = sales_data[['TV']]\n",
    "y = sales_data['Sales']\n",
    "\n",
    "lmreg.fit(x, y)\n",
    "\n",
    "print ('intercept : ', lmreg.intercept_)\n",
    "print ('Reg Coeficients : ', lmreg.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot TV vs Sales\n",
    "x_new = pd.DataFrame({'TV': [sales_data.TV.min(), sales_data.TV.max()]})\n",
    "y_pred = lmreg.predict(x_new)\n",
    "\n",
    "sales_data.plot(kind='scatter', x='TV', y='Sales')\n",
    "plt.plot(x_new, y_pred, c='red', linewidth=2)        # Model :  Sales = 5.93 +  0.064 * TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales = 5.93 +  0.064 * TV\n",
    "\n",
    "Interpreting the **intercept** ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when $x$=0.\n",
    "- Thus, it is the estimated number of sales of Products when the TV-Advertisement = $ 0K\n",
    "\n",
    "Interpreting the **\"TV\" coefficient** ($\\beta_1$):\n",
    "\n",
    "- It is the change in $y$ divided by change in $x$, or the \"slope\".\n",
    "- Thus, a TV-Advertisement increase of 1K budget is **associated with** with the Sale increase of 64 products (.064K) .\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **Positive** if an increase in TV-Adv Budgets was associated with a **Increase** in Sales of Products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction on the test data\n",
    "y_pred = lmreg.predict(x)\n",
    "\n",
    "# comparison of predictive vs Actual in test data\n",
    "comparision_df = pd.DataFrame()\n",
    "\n",
    "comparision_df['Actual_sales'] = y\n",
    "comparision_df['Predicted_sales'] = y_pred\n",
    "comparision_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn - Multiple Regregression Modeling\n",
    "- For multiple regression modeling, first sepeare all the important input attributes in the seperate data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the Input and output attributes in diff dataframes\n",
    "x = sales_data[['TV', 'Radio', 'Prod_type_cd']]\n",
    "y = sales_data['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn - Regregression Modeling Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1: Import the model class that is gong to be used - Regression Tree\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2: Create the instance of the Model Estimator (instantiate the model)\n",
    "lmreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - Test Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 split the whole data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: train the model based on training data to learn the pattern from historical data\n",
    "lmreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('intercept : ', lmreg.intercept_)\n",
    "print ('Reg Coeficients : ', lmreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales = 9.4 +  0.049 * TV  +  .13 * Radio  - 2.24 * Prod_type_cd   - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1k unit increase in **TV-Adv Budgets** is associated with a **Sales increase of .049K Products**.\n",
    "- Holding all other features fixed, a 1k unit increase in **Radio-Adv Budgets** is associated with a **Sales increase of .13K Products**.\n",
    "- Holding all other features fixed, ** Product Model with Medium ** is associated with a **Sales decrease of 2.24K Product** compared to the **Basic Model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Prediction on the test data\n",
    "y_test_pred = lmreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of predictive vs Actual in test data\n",
    "comparision_df = pd.DataFrame()\n",
    "\n",
    "comparision_df['Actual_sales'] = y_test\n",
    "comparision_df['Predicted_sales'] = y_test_pred\n",
    "comparision_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics for regression problems\n",
    "\n",
    "Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. \n",
    "We need evaluation metrics designed for comparing **continuous values**.\n",
    "\n",
    "Here are three common evaluation metrics for regression problems:\n",
    "\n",
    "**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n",
    "\n",
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "\n",
    "$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n",
    "\n",
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "\n",
    "$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictive performance on Train Data - RMSE uisng metrics function from sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "sales_test_pred = lmreg.predict(x_test)\n",
    "print('Test Predictive Error RMSE: ' , np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Package to perform the Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression model of Sales vs TV-ads\n",
    "lm_reg = smf.ols(formula='Sales ~ TV ', data=sales_data).fit()\n",
    "\n",
    "# Print the estimated coeficietns\n",
    "lm_reg.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot TV vs Sales\n",
    "x_new = pd.DataFrame({'TV': [sales_data.TV.min(), sales_data.TV.max()]})\n",
    "preds = lm_reg.predict(x_new)\n",
    "\n",
    "sales_data.plot(kind='scatter', x='TV', y='Sales')\n",
    "plt.plot(x_new, preds, c='red', linewidth=2)        # Sales = 5.696658 +  0.067300 * TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales = 5.696658 +  0.067300 * TV\n",
    "\n",
    "Interpreting the **intercept** ($\\beta_0$):\n",
    "\n",
    "- It is the value of $y$ when $x$=0.\n",
    "- Thus, it is the estimated number of sales of Products when the TV-Advertisement = $ 0K\n",
    "\n",
    "Interpreting the **\"TV\" coefficient** ($\\beta_1$):\n",
    "\n",
    "- It is the change in $y$ divided by change in $x$, or the \"slope\".\n",
    "- Thus, a TV-Advertisement increase of 1K budget is **associated with** with the Sale increase of 67 products (.067K) .\n",
    "- This is not a statement of causation.\n",
    "- $\\beta_1$ would be **Positive** if an increase in TV-Adv Budgets was associated with a **Increase** in Sales of Products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated regression model equation\n",
    "# Sales = 5.696658 +  0.067300 * TV\n",
    "\n",
    "# predict the products Sales, if TV ads budget = $100K\n",
    "Sales = 5.696658 +  0.067300 * 100\n",
    "Sales  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = pd.DataFrame({'TV': [100]})\n",
    "preds = lm_reg.predict(x_new); preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model summary\n",
    "print(lm_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated Regression Model Interpretation\n",
    "# Sales = 5.696658 +  0.067300 * TV\n",
    "\n",
    "# B0(intercept) = 5.696658 => In case of TV ads budget= $0k, the estimated product sales would be 5.7 K.\n",
    "# B1(slope)     = 0.067300 => for each unit increase in the TV ads budget (in thousand), the product sales would \n",
    "#                             increase on average by 0.06 K.\n",
    "\n",
    "#1: - F Test,  p<.05 => indicates that Model is significant predicting Sales based on TV ads predictor.\n",
    "#                             \n",
    "#2: - Adj Rsq = .47 => Indicates that around 47% of total sample Variation of the Response Sales is \n",
    "#                       explained by predictors TV ads.\n",
    "#\n",
    "#4: - t-test of predictors TV ads = p <.05 indicate that TV-ads is signinificant for predicting Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the R-squared (correlation as group variables vs Response)\n",
    "lm_reg.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption Test : - Hetroscadasticity using Goldfield Quandt \n",
    "#                    H0 - Residual Errors are Homoscadastic\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.compat import lzip\n",
    "result_name = ['F Statistic', 'P-value']\n",
    "test = sms.het_goldfeldquandt(lm_reg.resid, lm_reg.model.exog) \n",
    "lzip(result_name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression \n",
    "\n",
    "When we build the Regression Model with multiple features that is known as Multiple Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fitted model with all three features\n",
    "lm_multreg = smf.ols(formula='Sales ~ TV + Radio + Prod_type_cd', data=sales_data).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm_multreg.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales = 4.04 + TV * 0.066 + .12 * Radio  + .04 * Newspaper  - 2.44 * Prod_type_cd   - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the coefficients:\n",
    "\n",
    "- Holding all other features fixed, a 1k unit increase in **TV-Adv Budgets** is associated with a **Sales increase of .066K Products**.\n",
    "- Holding all other features fixed, a 1k unit increase in **Radio-Adv Budgets** is associated with a **Sales increase of .120K Products**.\n",
    "- Holding all other features fixed, a 1k unit increase in **Newspaper-Adv Budgets** is associated with a **Sales increase of .040K Products**.\n",
    "- Holding all other features fixed, ** Product Model with Medium ** is associated with a **Sales decrease of 2.44K Product** compared to the **Basic Model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_multreg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the future purchase demands based on below allocated budgets for basic model of product\n",
    "x_new = pd.DataFrame({'TV': [100], 'Radio':[50], 'Newspaper' :[20], 'Prod_type_cd' :[0]})\n",
    "lm_reg.predict(x_new)\n",
    "\n",
    "# Sales = 4.04 + TV * 0.066 + .12 * Radio  + .04 * Newspaper  - 2.44 * Prod_type_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_pred = lm_multreg.predict(sales_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparision_df = pd.DataFrame()\n",
    "comparision_df['Actual_Sales'] = sales_data.Sales\n",
    "comparision_df['Predicted_Sales'] = sales_pred\n",
    "comparision_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - Test Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictive Performance - divide the input data into train and test. \n",
    "from sklearn.model_selection import train_test_split\n",
    "sales_data_train, sales_data_test = train_test_split(sales_data, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_multreg = smf.ols(formula='Sales ~ TV + Radio + Prod_type_cd', data=sales_data_train).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm_multreg.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Model :   Sales = 3.3 + .06*TV + .14*Radio + .04*Newspaper - 2.19*Prod_type_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_test_pred = lm_multreg.predict(sales_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparision_df = pd.DataFrame()\n",
    "comparision_df['Actual_Sales'] = sales_data_test.Sales\n",
    "comparision_df['Predicted_Sales'] = sales_test_pred\n",
    "comparision_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictive performance on Train Data - RMSE uisng metrics function from sklearn\n",
    "sales_train_pred = lm_multreg.predict(sales_data_train)\n",
    "print('Train Predictive Error RMSE: ' , np.sqrt(metrics.mean_squared_error(sales_data_train.Sales, sales_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Predictive performance on Test Data - RMSE uisng metrics function from sklearn\n",
    "print('Test Predictive Error RMSE: ' , np.sqrt(metrics.mean_squared_error(sales_data_test.Sales, sales_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
